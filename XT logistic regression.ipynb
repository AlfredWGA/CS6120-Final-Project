{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CS 6120 logistic regression.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPRJr6RScLW75pWYbpVYVca"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iw7QCl-xQ3fl","executionInfo":{"status":"ok","timestamp":1619661062521,"user_tz":240,"elapsed":4868,"user":{"displayName":"Logan Tang","photoUrl":"","userId":"16215472149116219288"}},"outputId":"dd01068c-b2f4-4b63-94ba-2380e61608b9"},"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import cross_validate,LeaveOneOut,KFold\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import os\n","import numpy as np\n","import pandas as pd\n","from google.colab import drive\n","from tqdm import tqdm_notebook, tqdm\n","\n","drive.mount('/content/drive')\n","path = 'drive/My Drive/blogtext_preprocessed.csv'\n","blog_data = pd.read_csv(path).iloc[:10000,]"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_8Toe6OGRd7a","executionInfo":{"status":"ok","timestamp":1619661063431,"user_tz":240,"elapsed":286,"user":{"displayName":"Logan Tang","photoUrl":"","userId":"16215472149116219288"}}},"source":["def createBasicFeatures(data):\n","  data.dropna(inplace=True)\n","  data.replace({'gender': {'male': 1,'female': 0}},inplace=True)\n","  temp_text = data['text'].to_list()\n","  classes = data['gender'].to_list()\n","  # vectorizer = CountVectorizer(analyzer='word',token_pattern=r'\\d*[a-zA-Z][a-zA-Z0-9]*')\n","  vectorizer = TfidfVectorizer(analyzer='word',token_pattern=r'\\d*[a-zA-Z][a-zA-Z0-9]*')\n","  X = vectorizer.fit_transform(temp_text)\n","  vocab = vectorizer.get_feature_names()\n","  texts = X.toarray()\n","  return texts,classes,vocab\n","\n","def evaluateModel(X,y,vocab,penalty=\"l1\"):\n","  # create and fit the model\n","  model = LogisticRegression(penalty=penalty,solver=\"liblinear\")\n","  results = cross_validate(model,X,y,cv=KFold(n_splits=10, shuffle=True, random_state=1))\n","  \n","  # determine the average accuracy\n","  scores = results[\"test_score\"]\n","  avg_score = sum(scores)/len(scores)\n","  \n","  # determine the most informative features\n","  # this requires us to fit the model to everything, because we need a\n","  # single model to draw coefficients from, rather than 26\n","  model.fit(X,y)\n","  class0_weight_sorted = model.coef_[0, :].argsort()\n","  class1_weight_sorted = (-model.coef_[0, :]).argsort()\n","\n","  termsToTake = 20\n","  class0_indicators = [vocab[i] for i in class0_weight_sorted[:termsToTake]]\n","  class1_indicators = [vocab[i] for i in class1_weight_sorted[:termsToTake]]\n","\n","  if model.classes_[0] == \"pos\":\n","    return avg_score,class0_indicators,class1_indicators\n","  else:\n","    return avg_score,class1_indicators,class0_indicators\n","\n","def runEvaluation(X,y,vocab):\n","  print(\"----------L1 Norm-----------\")\n","  avg_score,pos_indicators,neg_indicators = evaluateModel(X,y,vocab,\"l1\")\n","  print(\"The model's average accuracy is %f\"%avg_score)\n","  print(\"The most informative terms for pos are: %s\"%pos_indicators)\n","  print(\"The most informative terms for neg are: %s\"%neg_indicators)\n","  #this call will fit a model with L2 normalization\n","  print(\"----------L2 Norm-----------\")\n","  avg_score,pos_indicators,neg_indicators = evaluateModel(X,y,vocab,\"l2\")\n","  print(\"The model's average accuracy is %f\"%avg_score)\n","  print(\"The most informative terms for pos are: %s\"%pos_indicators)\n","  print(\"The most informative terms for neg are: %s\"%neg_indicators)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3uCY7WoIRlaR","executionInfo":{"status":"ok","timestamp":1619661110887,"user_tz":240,"elapsed":45146,"user":{"displayName":"Logan Tang","photoUrl":"","userId":"16215472149116219288"}},"outputId":"d9edda71-c9ed-4833-c368-7c3276bf291b"},"source":["X,y,vocab = createBasicFeatures(blog_data)\n","runEvaluation(X, y, vocab)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["----------L1 Norm-----------\n","The model's average accuracy is 0.751522\n","The most informative terms for pos are: ['duf', 'hal', 'dj', 'f', 'ben', 'panda', 'pandyland', 'stoner', 'chicago', 'agre', 'korean', 'album', 'angi', 'cowork', 'johnathan', 'seoul', 'ash', 'bb', 'sinc', 'film']\n","The most informative terms for neg are: ['diva', 'ked', 'lar', 'dun', 'lol', 'heart', 'quizilla', 'chantel', 'rachel', 'buddi', 'fall', 'ppl', 'hurt', 'beach', 'eg', 'jame', 'sit', 'sarah', 'theo', 'poem']\n","----------L2 Norm-----------\n","The model's average accuracy is 0.764718\n","The most informative terms for pos are: ['duf', 'dj', 'hal', 'ben', 'panda', 'stoner', 'angi', 'pandyland', 'korean', 'fer', 'agre', 'f', 'johnathan', 'album', 'hey', 'sinc', 'play', 'bush', 'but', 'chicago']\n","The most informative terms for neg are: ['diva', 'ked', 'lol', 'heart', 'quizilla', 'realli', 'fall', 'urllink', 'hurt', 'i', 'never', 'fuck', 'ya', 'dun', 'lar', 'fun', 'sit', 'till', 'mayb', 'ppl']\n"],"name":"stdout"}]}]}